{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5ceb88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "import xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e71d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = 'F:/github-project/shiyan/shiyan5/第五章 话题追踪与检测/话题检测/tc-corpus-answer/answer/'\n",
    "dir_names = os.listdir(path_data)\n",
    "labels,texts=[],[]\n",
    "for dir_name in dir_names:\n",
    "    file_names =os.listdir(path_data + dir_name +'/')\n",
    "    for file_name in file_names:\n",
    "        f = open(path_data + dir_name + '/'+ file_name, encoding='gb18030', errors='ignore')\n",
    "        content = f.read()\n",
    "        f.close()\n",
    "        labels.append(dir_name)\n",
    "        texts.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba14c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pandas.DataFrame()\n",
    "trainDF[\"text\"] = texts\n",
    "trainDF[\"label\"] = labels\n",
    "train_x,valid_x,train_y,valid_y = model_selection.train_test_split(trainDF[\"text\"],trainDF[\"label\"])\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)\n",
    "count_vect = CountVectorizer(analyzer=\"word\", token_pattern=r\"\\w{1,}\")\n",
    "count_vect.fit(trainDF[\"text\"])\n",
    "xtrain_count = count_vect.transform(train_x)\n",
    "xvalid_count = count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9748f8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:555: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 词语级tf-idf\n",
    "tfidf_vect = TfidfVectorizer(\n",
    "    analyzer=\"word\", token_pattern=r\"\\w{1,}\", max_features=5000\n",
    ")\n",
    "tfidf_vect.fit(trainDF['text'])\n",
    "xtrain_tfidf = tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf = tfidf_vect.transform(valid_x)\n",
    "# ngram 级tf-idf\n",
    "tfidf_vect_ngram = TfidfVectorizer(\n",
    "    analyzer=\"word\", token_pattern=r\"\\w{1,}\", ngram_range=(2, 3), max_features=5000\n",
    ")\n",
    "tfidf_vect_ngram.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram = tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram = tfidf_vect_ngram.transform(valid_x)\n",
    "# 词性级tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(\n",
    "    analyzer=\"char\", token_pattern=r\"\\w{1,}\", ngram_range=(2, 3), max_features=5000\n",
    ")\n",
    "tfidf_vect_ngram_chars.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(train_x)\n",
    "xvalid_tfidf_ngram_chars = tfidf_vect_ngram_chars.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02106892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train,label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifien\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    # predict the labels on validation dataset\n",
    "    predictions =classifier.predict(feature_vector_valid)\n",
    "    if is_neural_net:\n",
    "        predictions =predictions.argmax(axis=-1)\n",
    "        return metrics.accuracy_score(predictions,valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8821a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB,Count Vectors: None\n",
      "NB,WordLevel TF-IDF: None\n",
      "NB,N-Gram Vectors: None\n",
      "NB,CharLevel Vectors: None\n"
     ]
    }
   ],
   "source": [
    "# 特征为计数向量的朴素贝叶斯\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(),xtrain_count, train_y, xvalid_count)\n",
    "print(\"NB,Count Vectors:\",accuracy)\n",
    "# 特征为词语级别TF-IDF向量的朴素贝叶斯\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(),xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"NB,WordLevel TF-IDF:\",accuracy)\n",
    "#特征为多个词语级别TF-IDF向量的朴素贝叶斯\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"NB,N-Gram Vectors:\",accuracy)\n",
    "# 特征为词性级别TF-IDF向量的朴素贝叶斯\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"NB,CharLevel Vectors:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59dadac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR,Count Vectors: None\n",
      "LR,WordLevel TF-IDF: None\n",
      "LR,N-Gram Vectors: None\n",
      "LR,CharLevel Vectors: None\n"
     ]
    }
   ],
   "source": [
    "#特征为计数向量的线性分类器\n",
    "accuracy = train_model(linear_model.LogisticRegression(),xtrain_count, train_y, xvalid_count)\n",
    "print(\"LR,Count Vectors:\",accuracy)\n",
    "#特征为词语级别TF-IDF向量的线性分类器\n",
    "accuracy = train_model(linear_model.LogisticRegression(),xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"LR,WordLevel TF-IDF:\",accuracy)\n",
    "#特征为多个词语级别TF-IDF向量的线性分类器\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"LR,N-Gram Vectors:\",accuracy)\n",
    "# 特征为词性级别TF-IDF向量的线性分类器\n",
    "accuracy = train_model(linear_model.LogisticRegression(),xtrain_tfidf_ngram_chars, train_y,xvalid_tfidf_ngram_chars)\n",
    "print(\"LR,CharLevel Vectors:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "187a003f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 特征为多个词语级别TF-IDF向量的SVM\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m train_model(svm\u001b[38;5;241m.\u001b[39mSvc(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVM,N-Gram Vectors:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 特征为计数向量的RF\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'svm' is not defined"
     ]
    }
   ],
   "source": [
    "# 特征为多个词语级别TF-IDF向量的SVM\n",
    "accuracy = train_model(svm.Svc(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"SVM,N-Gram Vectors:\", accuracy)\n",
    "# 特征为计数向量的RF\n",
    "accuracy = train_model(\n",
    "    ensemble.Randomforestclassifier(), xtrain_count, train_y, xvalid_count\n",
    ")\n",
    "print(\"RF,Count Vectors:\", accuracy)\n",
    "# 特征为词语级别TF-IDF向量的RF\n",
    "accuracy = train_model(\n",
    "    ensemble.Randomforestclassifier(), xtrain_tfidf, train_y, xvalid_tfidf\n",
    ")\n",
    "print(\"RF,WordLevel TF-IDF:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a75fb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征为计数问量的Xgboost\n",
    "accuracy = train_model(xgboost.xGBclassifier(), xtrain_count.tocsc(), train_y, xvalid_count.tocsc())\n",
    "print(\"Xgb,Count Vectors:\",accuracy)\n",
    "# 特征为词语级别TF-IDF向量的Xgboost\n",
    "accuracy = train_model(xgboost.xGBclassifier(), xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc())\n",
    "print(\"Xgb,WordLevel TF-IDF:\",accuracy)\n",
    "# 特征为词性级别TF-IDF向量的Xgboost\n",
    "accuracy = train_model(xgboost.XGBclassifier(),xtrain_tfidf_ngram_chars.tocsc(), train_y,xvalid_tfidf_ngram_chars.tocsc())\n",
    "print(\"Xgb, CharLevel Vectors:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31592634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_architecture(input_size):\n",
    "    # create input layer\n",
    "    input_layer = layers.Input((input_size,),sparse=True)\n",
    "    # create hidden layer\n",
    "    hidden_layer = layers.Dense(100, activation=\"relu\")(input_layer)\n",
    "    # create output layer\n",
    "    output_layer = layers.Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
    "    classifien = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "    classifier.compile(optimizer=optimizers.Adam(),loss='binary_crossentropy')\n",
    "    return classifier\n",
    "#浅层神经网络\n",
    "classifier = create_model_architecture(xtrain_tfidf_ngram.shape[1])\n",
    "accuracy = train_model(classifier, xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram, is_neural_net=True)\n",
    "print(\"NN,Ngram Level TF IF Vectors\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
